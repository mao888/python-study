#1 人工智能概论
##了解掌握人工智能的基本概念与定义
定义：研究、开发用于模拟、延伸和扩展人的智能的理论、方法、技术及应用系统的一门新的技术科学。人工智能是研究使计算机来模拟人的某些思维过程和智能行为（如学习、推理、 思考、规划等）的学科，主要包括计算机实现智能的原理、制造类似 于人脑智能的计算机，使计算机能实现更高层次的应用。
概念：
1. “弱人工智能（Artificial Narrow Intelligence，ANI）”是指能根据人类设计的某种算法依托计算机进行基本逻辑推理（Reasoning）和解决某种特定问题（Problem-solving）的智能。弱人工智能在某一方面表现出智能，但是不具有与人类相当的智力水平和思维模式。
2. “强人工智能（Artificial General Intelligence，AGI）”有时也叫通用人工智能（GeneralArtificialIntelligence）或完全人工智能（FullAI），指的是可以胜任人类所有工作的人工智能，能够进行思考计划、解决问题、抽象思维、理解复杂理念、快速学习和从经验中学习，具备在存在不确定性因素时进行推理、使用策略、解决问题、制订决策的能力，使用自然语言进行交流沟通的能力及将上述能力整合以实现既定目标的能力。
3. “超人工智能（Artificial Super Intelligence，ASI）”是指随着科学技术的不断发展和协同工作，让计算机创造出一种在科学创新、通识和社交技能等方面都比人类大脑聪明很多的智能。“超人工智能”寄托着人类美好的愿景但不一定能够达到的目标。
##了解人工智能的主要学派及主旨思想
###符号主义
“符号主义”研究者认为人工智能源于数理逻辑。数理逻辑从19世纪末得以迅速发展，到20世纪30年代开始用于描述智能行为。启发式程序逻辑理论家LT（Logic Theorist），它证明了38条数学定理，表明可以应用计算机研究人的思维过程来模拟人类智能活动。在此基础上，符号主义学派发展了启发式算法→专家系统→知识工程理论与技术，并在20世纪80年代取得很大发展。符号主义仍然是人工智能的主流派别，这个学派的代表人物有纽厄尔（Newell）、西蒙 （Simon）、尼尔逊（Nilsson）等。大数据知识工程的知识图谱（Knowledge Graph）是符号主义学派人工智能代表性应用成果，在知识图谱的带动下，自然语言理解 （Natural Language Processing，NLP）取得了飞速进展并获得了长足进步
###连接主义学派
每个人的大脑都有上百亿个神经元细胞，它们错综复杂地互相连接，也被认为是人类智慧的来源，人们想到能否通过大量神经元来模拟人类大脑的智力。基于此，“连接主义”研究者认为神经网络和神经网络间的连接机制和学习方法能够产生智能。20世纪60—70年代，连接主义对以感知机（Perceptron）为代表的脑模型的研究出现过热潮，理论模型、生物原型和技术条件的限制，脑模型研究在20世纪70年代后期至80年代初期落入低潮。
直到美国John J.Hopfield教授在1982年和1984年发表两篇重要论文，提出用硬件模拟神经网络以后，连接主义才又重新引发关注。1986年，鲁梅尔哈特（Rumelhart）等提出多层网络中的反向传播算法（ Back Propagation ， BP ）算法 。 此后又有卷积神经网（Convolutional Neural Networks，CNN）的研究，连接主义开始重新焕发生命力，从模型到算法，从理论分析到工程实现，为基于神经网络的人工智能走向市场打下基础。
###行为主义学派
“行为主义”研究者认为人工智能源于控制论。维纳（Wiener）和麦卡洛克（McCulloch）等提出的控制论 和自组织系统及钱学森等人提出的工程控制论和生物控制论影响了许 多领域。控制论把神经系统的工作原理与信息理论、控制理论、逻辑 及计算机联系起来。
到20世纪60—70年代，上述这些对控制论系统的研究取得一定进展，播下智能控制和智能机器人的种子，并在20世纪80年代诞生了智能控制和智能机器人系统。行为主义是20世纪末才以人工智能新学派的面孔出现的，引起许多人的兴趣。当前行为主义人工智能研究走在世界前列的无疑是波士 顿动力（Boston Dynamics）机器人
##了解掌握人工智能的起源与发展历程
1. 起步发展期：1956年—20世纪60年代初。人工智能概念提出后，相继取得了一批令人瞩目的研究成果，如机器定理证明、跳棋程序等，掀起人工智能发展的第一个高潮。

2. 反思发展期：20世纪60—70年代初。人工智能发展初期的突破性进展大大提升了人们对人工智能的期望，人们开始尝试更具挑战性的任务，并提出了一些不切实际的研发目标。然而，接二连三的失败和预期目标的落空，例如无法用机器证明两个连续函数之和还是连续函数、机器翻译闹出笑话等，使人工智能的发展走入低谷。

3. 应用发展期：20世纪70年代初—80年代中。20世纪70年代出现的专家系统模拟人类专家的知识和经验解决特定领域的问题，实现了人工智能从理论研究走向实际应用、从一般推理策略探讨转向运用专门知识的重大突破。专家系统在医疗、化学、地质等领域取得成功，推动人工智能走入应用发展的新高潮。

4. 低迷发展期：20世纪80年代中—90年代中。随着人工智能的应用规模不断扩大，专家系统存在的应用领域狭窄、缺乏常识性知识、知识获取困难、推理方法单一、缺乏分布式功能、难以与现有数据库兼容等问题逐渐暴露出来。
5. 稳步发展期：20世纪90年代中—2010年。由于网络技术特别是互联网技术的发展，加速了人工智能的创新研究，促使人工智能技术进一步走向实用化。1997年国际商业机器公司（IBM）深蓝超级计算机战胜了国际象棋世界冠军卡斯帕罗夫，2008年IBM提出“智慧地球”的概念等都是这一时期的标志性事件。

6. 蓬勃发展期：2011年至今。随着大数据、云计算、互联网、物联网、智能手机、北斗定位、5G通信等新一代信息技术的发展，泛在感知数据和图形处理器等计算平台推动以深度神经网络为代表的人工智能技术飞速发展，大幅跨越了科学与应用之间的“技术鸿沟”，诸如图像分类、语音识别、知识问答、人机对弈、无人驾驶等人工智能技术实现了从“不能用、不好用”到“可以用”的技术突破，迎来爆发式增长的新高潮。
##了解掌握驱动新一代人工智能快速发展的数据、算法、算力等重要驱动因素
算法进步(深度学习) 
创新应用(视频理解，自然语言处理)
移动互联网(智能手机+4G/5G)
算力提神(GPU并行计算)
数据能力增强(大数据技术)
以深度学习（Deep Learning，DL）为代表的人工智能异军突起，在计算机视觉、自然语言处理等领域取得了很好的效果，成为主导新一轮人工智 能发展的主力军，大数据（Big Data）的发展为深度学习注入了新的“燃料”，极大地提高了深度学习的智能水平。计算能力的提升促进了深度学习模型的训练效率，成为推动新一代人工智能发展的主要驱动力。移动互联网与智能手机的结合为新一代人工智能插上腾飞的翅膀，产生了全新的应用，如语音购物、人脸支付、视频理解、自然语言处理、无人超市、自动驾驶等。
##了解掌握机器学习、计算机视觉、自然语言处理、知识图谱、人机交互、机器人技术、SLAM 技术等主要人工智能技术的基本概念和应用场景
机器学习
概念：是一门涉及统计学、系统辨 识、逼近理论、神经网络、优化理论、计算机科学、脑科学等诸多领域的交叉学科，研究计算机怎样模拟或实现人类的学习行为，以获取新的知识或技能，重新组织已有的知识结构使之不断改善自身的性能，是人工智能技术的核心。
应用场景：深度学习是学习样本数据的内在规律和表示层次，这些学习过程中获得的信息对诸如文字、图像和声音等数据的解释有很大的帮助。它的最终目标是让机器能够像人一样具有分析学习能力，能够 识别文字、图像和声音等数据。
知识图谱
概念：知识图谱本质上是结构化的语义知识库，是一种由节点和边组成的图数据结构，以符号形式描述物理世界中的概念及其相互关系，其基本组成单位是“实体—关系—实体”三元组， 以及实体及其相关 “属性—值”对。
自然语言处理
概念：研究能实现人与计算机之间用自然语言进行有效通信的各种理论 和方法，涉及的领域较多，主要包括机器翻译(机器翻译技术是指利用计算机技术实现从一种自然语言到另外一种自然语言的翻译过程)、机器阅读理解(语义理解技术是指利用计算机技术实现对文本篇章的理解，并且回答与篇章相关问题的过程)和问答系统(问答系统技术是指让计算机像人类一样用自然语言与人交流的技术)
自然语言处理面临四大挑战：
一是在词法、句法、语义、语用和语音等不同层面存在不确定 性；
二是新的词汇、术语、语义和语法导致未知语言现象的不可预测 性；
三是数据资源的不充分使其难以覆盖复杂的语言现象；
四是语义知识的模糊性和错综复杂的关联性难以用简单的数学模型描述，语义计算需要参数庞大的非线性计算。

人机交互
人机交互主要研究人和计算机之间的信息交换，主要包括人到计 算机和计算机到人的两部分信息交换，是人工智能领域重要的外围技术。
##掌握深度学习的概念与原理，深度学习与传统机器学习的区别与联系
深度学习是学习样本数据的内在规律和表示层次，这些学习过程中获得的信息对诸如文字、图像和声音等数据的解释有很大的帮助。它的最终目标是让机器能够像人一样具有分析学习能力，能够识别文字、图像和声音等数据。
深度学习(机器学习的一个子集：利用多层神经网络从大量数据中进行学习)
$\subset$机器学习(能够随着数据的增加不断改进性能的算法)
$\subset$人工智能(感知道，推理，行动和适应的程序)
##掌握深度学习的训练方法，掌握特征、权重等概念，以及监督学习与无监督学习、半监督学习的区别
1. 有监督学习：将训练样本的数据加入到神经网络的输入端，将期望答案和实际输出做差，可以得到误差信号，通过误差信号来调整权值大小，以此来优化模型输出。
2. 无监督学习：首先并不给定标准数据样本，而是直接将网络置于环境之中，由自身根据数据特征进行自动学习。
3. 半监督学习：输入信息介于有监督和无监督之间，不需要给定标准数据样本，但需要对网络的输出做出评判，以此来调整网络参数。
##掌握感知器模型的原理，激活函数的常用类型
##掌握反向传播算法的基本原理和整体步骤流程
##掌握梯度下降法的基本原理和算法流程
##掌握交叉熵损失函数的定义和python代码实现
在神经网络中较常采用交叉熵（Binary Cross (ntropy)作为损失函数，设p表示真实标记的分布，q则为训练后的模型的预测标记分布，交叉熵损失函数可以衡量p与q的相似性。交叉熵作为损失函数还 有一个好处，使用Sigmoid函数在梯度下降时能避免均方误差损失函数 学习速率降低的问题，因为学习速率可以被输出的误差所控制。
定义：
$
\left.C=\dfrac{1}{n}\sum_{i=1}^{n}\left[\begin{matrix}y_{i}\ln\sigma(w^\mathrm{T}x_{i})+(1-y_{i})\ln(1-\sigma(w^\mathrm{T}x_{i}))\end{matrix}\right.\right]
$
程序：
```
def binary_crossentropy(t,o):
    return-(t?tf.log(o+eps)+(1.0-t)?tf.log(1.0-o+eps))
```
##掌握过拟合的概念以及防止过拟合的常用方法
过拟合常见的解决办法有以下几种。 
1. 在神经网络模型中，可使用权值衰减的方法，即每次迭代过程中以某个小因子降低每个权值。 
2. 选取合适的停止训练标准，使对机器的训练在合适的程度。 
3. 保留验证数据集，对训练成果进行验证。 
4. 获取额外数据进行交叉验证。 
5. 正则化，即在进行目标函数或代价函数优化时，在目标函数或代价函数后面加上一个正则项，一般有L1正则与L2正则等。

<!-- 欠拟合的情况比较容易克服，常见解决方法有以下几种。 
1. 增加新特征，可以考虑加入特征组合、高次特征，以此增大假设空间。 
2. 添加多项式特征，这个在机器学习算法里用得很普遍，例如将线性模型通过添加二次项或者三次项使模型泛化能力更强。 
3. 减少正则化参数，正则化的目的是用来防止过拟合，但是模 型出现了欠拟合，则需要减少正则化参数。 
4. 使用非线性模型，例如支持向量机、决策树、深度学习等模型。 
5. 调整模型的容量（Capacity），通俗地讲，模型的容量是指其拟合各种函数的能力。 
6. 容量低的模型可能很难拟合训练集；使用集成学习方法，如使用Bagging，可将多个弱学习器Bagging。  -->
##掌握卷积神经网络的结构、各模块的计算、softmax的用途及计算方式，了解卷积网络的常用模型。
1. 输入层（Input Layer）。输入层是整个神经网络的输入，在处理图像的卷积神经网络中，它一般代表了一张图片的像素矩阵。 其中三维矩阵的长和宽代表了图像的大小，深度代表了图像的色彩通道（Channel）。例如黑白图的深度为1，而在RGB色彩模式下，图像的深度为3。从输入层开始，卷积神经网络通过不同的神经网络架构将上 一层的三维矩阵转换为下一层的三维矩阵，直到最后的全连接层。
2. 卷积层（Convolution Layer）。卷积层是一个网络最重要的部分，卷积层试图将神经网络中的每小块进行更加深入地分析从而获得抽象度更高的特征。一般来说，通过卷积层处理过的节点矩阵会变得更深。
3. 池化层（Pooling Layer）。池化层神经网络不会改变三维矩阵的深度，但是它可以缩小矩阵的大小。通过池化层可以进一步缩小最后全连接层中节点的个数，从而达到减小整个神经网络参数的目的。
4. 全连接层（Full Connection Layer）。在经过多轮卷积和池化之后，在卷积神经网络的最后一般会有1～2个全连接层给出最后的分类结果。经过几轮卷积和池化之后，可以认定图像中的信息已经 被抽象成信息含量更高的特征。我们可以将卷积层和池化层看作自动图像特征提取的过程，在特征提取之后，仍要用全连接层来完成分类问题。
5. Softmax层。Softmax层主要用于分类问题，通过Softmax层 可以得到当前输出属于不同种类的概率分布情况。 该层主要采用 Softmax函数，又称归一化指数函数，是对数概率回归在的推广，公式如下：
$  \begin{aligned}\operatorname{Softmax}(i)&=\frac{\mathrm{e}^{-O_i}}{\sum\limits_{j=1}^C\mathrm{e}^{-O_j}}\quad i=1,2,\cdots,C-1\\\end{aligned}$
#2 Python 编程基础
##了解掌握Python语言的特点与发展
##掌握Python语言基本语法与数据类型
##掌握常用函数的功能与用法
##熟练使用基本数据类型与组合数据类型
##掌握Python程序分支、循环等结构控制，掌握异常处理方法##掌握常用Python函数定义、调用及参数传递方法
##掌握程序中变量作用域、返回值类型
##掌握代码复用及模块化编程方法
##掌握Python面向对象编程方法，熟悉类的定义与使用、属性和方法的定义与使用、类的继承等
##掌握Python文件系统读、写等基本方法和操作
##掌握Python常用工具包，例如线性代数、可视化等
#3 概率统计基础
##概率基础知识，例如概率分布、联合概率、边缘概率、条件概率等基本概念
##掌握离散随机变量、连续随机变量的主要性质，了解掌握伯努利分布、泊松分布、均匀分布、正态分布等常用概率分布的公式与参数
##掌握样本的概念和性质，统计量的定义与性质，三大抽样分布函数的定义
##掌握大数定理和中心极限定理
##掌握参数估计的定义，掌握点估计、极大似然估计方法的原理；掌握评价估计量的标准、区间估计的概念和方法。
